{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-12T07:42:08.028665Z",
     "iopub.status.busy": "2023-11-12T07:42:08.027941Z",
     "iopub.status.idle": "2023-11-12T07:42:13.937431Z",
     "shell.execute_reply": "2023-11-12T07:42:13.936175Z",
     "shell.execute_reply.started": "2023-11-12T07:42:08.028608Z"
    }
   },
   "outputs": [],
   "source": [
    "import optuna\n",
    "import os\n",
    "import importlib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from functools import partial\n",
    "from pytorch_lightning.callbacks import EarlyStopping\n",
    "\n",
    "from darts import TimeSeries\n",
    "from darts.models import *\n",
    "from darts.metrics import rmse, coefficient_of_variation\n",
    "from darts.dataprocessing.transformers import Scaler\n",
    "from darts.utils.timeseries_generation import datetime_attribute_timeseries\n",
    "\n",
    "from time_series_model.data.weather.weather_dataloader import MeteostatDataLoader\n",
    "from time_series_model.data.data_loading import SMARDDataLoader\n",
    "from time_series_model import evaluation\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import logging\n",
    "logging.getLogger(\"time_series_model\").setLevel(logging.INFO)\n",
    "logging.getLogger('lightning').setLevel(0)\n",
    "logging.getLogger('pytorch_lightning').setLevel(0)\n",
    "logging.getLogger('darts').setLevel(0)\n",
    "logging.basicConfig(format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the weather data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meteostat_data_loader = MeteostatDataLoader(\n",
    "    file_paths=[\n",
    "        os.path.join(os.getcwd(), os.pardir, 'data', 'raw', 'weather_data_solar_stations.csv')\n",
    "    ],\n",
    "    solar=True,\n",
    "    wind=True\n",
    ")\n",
    "meteostat_data_loader.load_data()\n",
    "weather_data = meteostat_data_loader.data\n",
    "\n",
    "print(\"Missing values\")\n",
    "for col in weather_data.columns:\n",
    "    print(f\"  Column {col} has {weather_data[col].isna().mean() * 100:0.2f}% missing values\")\n",
    "\n",
    "weather_data['time'] = pd.to_datetime(weather_data['time'])\n",
    "weather_data = weather_data.set_index('time')\n",
    "print(f\"Weather data index: {weather_data.index.min()} - {weather_data.index.max()}\")\n",
    "\n",
    "weather_data = TimeSeries.from_dataframe(\n",
    "    weather_data, \n",
    "    value_cols=list(weather_data.columns), \n",
    "    fill_missing_dates=True, \n",
    "    fillna_value=0, \n",
    "    freq='1H'\n",
    ")\n",
    "# To float32\n",
    "weather_data = weather_data.astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load SMARD data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-12T07:42:13.946255Z",
     "iopub.status.busy": "2023-11-12T07:42:13.945973Z",
     "iopub.status.idle": "2023-11-12T07:42:14.243019Z",
     "shell.execute_reply": "2023-11-12T07:42:14.242307Z",
     "shell.execute_reply.started": "2023-11-12T07:42:13.946220Z"
    }
   },
   "outputs": [],
   "source": [
    "smard_dataloader = SMARDDataLoader(\n",
    "    file_paths=[\n",
    "        os.path.join(os.getcwd(), os.pardir, 'data', 'raw', '2015_2016.csv'),\n",
    "        os.path.join(os.getcwd(), os.pardir, 'data', 'raw', '2017_2018.csv'),\n",
    "        os.path.join(os.getcwd(), os.pardir, 'data', 'raw', '2019_2020.csv'),\n",
    "        os.path.join(os.getcwd(), os.pardir, 'data', 'raw', '2021_2022.csv'),\n",
    "        os.path.join(os.getcwd(), os.pardir, 'data', 'raw', '2022_2023.csv')\n",
    "    ]\n",
    ")\n",
    "smard_dataloader.load_data()\n",
    "smard_dataloader.preprocess_data()\n",
    "smard_dataloader.validate_data()\n",
    "\n",
    "smard_data = smard_dataloader.data\n",
    "smard_data['timestamp'] = pd.to_datetime(smard_data['timestamp'])\n",
    "smard_data = smard_data.set_index('timestamp')\n",
    "smard_data = TimeSeries.from_dataframe(\n",
    "    smard_data, \n",
    "    value_cols=list(smard_data.columns), \n",
    "    fill_missing_dates=True, \n",
    "    fillna_value=0, \n",
    "    freq='1H'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot weather data\n",
    "weather_data[-365:].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create synthetic date-time covariates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weekday = datetime_attribute_timeseries(weather_data, attribute=\"weekday\", dtype=np.float32)\n",
    "month = datetime_attribute_timeseries(weather_data, attribute=\"month\", dtype=np.float32)\n",
    "hour = datetime_attribute_timeseries(weather_data, attribute=\"hour\", dtype=np.float32)\n",
    "covariates_time = weekday.stack(hour).stack(month)\n",
    "\n",
    "scaler_covariates = Scaler()\n",
    "covariates_time = scaler_covariates.fit_transform(\n",
    "    covariates_time\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,2))\n",
    "covariates_time[-5*7*24:].plot()\n",
    "plt.title(\"Covariates Time\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/Val/Test split for SMARD data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-12T07:45:59.446369Z",
     "iopub.status.busy": "2023-11-12T07:45:59.446018Z",
     "iopub.status.idle": "2023-11-12T07:45:59.454112Z",
     "shell.execute_reply": "2023-11-12T07:45:59.452890Z",
     "shell.execute_reply.started": "2023-11-12T07:45:59.446343Z"
    }
   },
   "outputs": [],
   "source": [
    "smard_data_scaler = Scaler()\n",
    "scaled_smard_data = smard_data_scaler.fit_transform(smard_data)\n",
    "\n",
    "test_split = 0.15\n",
    "val_split = 0.15\n",
    "train_end_index = (1 - val_split - test_split) * len(scaled_smard_data)\n",
    "val_end_index = (1 - test_split) * len(scaled_smard_data)\n",
    "train_end_index, val_end_index = int(train_end_index), int(val_end_index)\n",
    "\n",
    "print(train_end_index, val_end_index)\n",
    "\n",
    "train, val, test = scaled_smard_data[:train_end_index], scaled_smard_data[train_end_index:val_end_index], scaled_smard_data[val_end_index:]\n",
    "\n",
    "# Cut train to start of weather data\n",
    "train = train[weather_data.start_time():]\n",
    "\n",
    "print(\"Train size: \", len(train))\n",
    "print(\"Val size: \", len(val))\n",
    "print(\"Test size: \", len(test))\n",
    "\n",
    "print(\"Train time boundaries: \", train.start_time(), train.end_time(), len(train) / 24)\n",
    "print(\"Val time boundaries: \", val.start_time(), val.end_time(), len(val) / 24)\n",
    "print(\"Test time boundaries: \", test.start_time(), test.end_time(), len(test) / 24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,2))\n",
    "train[-24*7:].plot()\n",
    "plt.title(\"Data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_model(model):\n",
    "    covariate_args = evaluation.get_covariate_args(\n",
    "        model=model,\n",
    "        covariates=covariates_time.stack(weather_data),\n",
    "    )[0]\n",
    "    model.fit(series=train, val_series=val, **covariate_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_lstm = RNNModel(\n",
    "    model=\"LSTM\", \n",
    "    input_chunk_length=24, \n",
    "    training_length=24 * 2,\n",
    "    hidden_dim=16,  \n",
    "    n_rnn_layers=1,\n",
    "    n_epochs=1,\n",
    "    force_reset=True\n",
    ")\n",
    "\n",
    "fit_model(simple_lstm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(evaluation)\n",
    "\n",
    "# Evaluate\n",
    "eval_result = evaluation.cross_validation_without_refit(\n",
    "    model=simple_lstm,\n",
    "    prefix_series=train,\n",
    "    test_series=val, \n",
    "    metrics={\n",
    "        'rmse': rmse, \n",
    "        'rmse_test': partial(evaluation.co2_rmse, disable_weights=True),\n",
    "        'co2_rmse': evaluation.co2_rmse, \n",
    "    },\n",
    "    data_scaler=smard_data_scaler,\n",
    "    covariates=covariates_time.stack(weather_data),\n",
    "    max_n_split=5,\n",
    "    forecast_horizon=24,\n",
    ")\n",
    "eval_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "\n",
    "    input_chunk_length = trial.suggest_int('input_chunk_length', 24, 24 * 7 * 4)\n",
    "    hidden_dim = trial.suggest_categorical('hidden_dim', [32, 64, 128, 256])\n",
    "    dropout = trial.suggest_float('dropout', 0.0, 0.5)\n",
    "    n_rnn_layers = trial.suggest_int('n_rnn_layers', 1, 3)\n",
    "    n_epochs = 20\n",
    "\n",
    "    print(f\"Trialing with {trial.params}\")\n",
    "\n",
    "    my_stopper = EarlyStopping(\n",
    "        monitor=\"val_loss\",\n",
    "        patience=5,\n",
    "        min_delta=0.05,\n",
    "        mode='min',\n",
    "    )\n",
    "    pl_trainer_kwargs = {\"callbacks\": [my_stopper]}\n",
    "\n",
    "    lstm_model = RNNModel(\n",
    "        model=\"LSTM\", \n",
    "        input_chunk_length=input_chunk_length, \n",
    "        training_length=input_chunk_length * 2,\n",
    "        hidden_dim=hidden_dim, \n",
    "        dropout=dropout, \n",
    "        n_rnn_layers=n_rnn_layers,\n",
    "        n_epochs=n_epochs,\n",
    "        pl_trainer_kwargs=pl_trainer_kwargs,\n",
    "        force_reset=True\n",
    "    )\n",
    "\n",
    "    fit_model(lstm_model)\n",
    "\n",
    "    # Evaluate\n",
    "    eval_result = evaluation.cross_validation_without_refit2(\n",
    "        model=lstm_model,\n",
    "        prefix_series=train,\n",
    "        test_series=val,\n",
    "        metrics={\n",
    "            'rmse': rmse, \n",
    "            'co2_rmse': evaluation.co2_rmse, \n",
    "        },\n",
    "        data_scaler=smard_data_scaler,\n",
    "        covariates=covariates_time.stack(weather_data),\n",
    "        forecast_horizon=7*24,\n",
    "    ) \n",
    "\n",
    "    eval_co2_rmse = eval_result['co2_rmse']\n",
    "    print(f\"Eval CO2 RMSE: {eval_co2_rmse}\")\n",
    "\n",
    "    return eval_co2_rmse\n",
    "\n",
    "# Create a study object and optimize the objective function.\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = study.best_params\n",
    "print(f\"Best params: {best_params}\")\n",
    "\n",
    "my_stopper = EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    patience=5,\n",
    "    min_delta=0.05,\n",
    "    mode='min',\n",
    ")\n",
    "pl_trainer_kwargs = {\"callbacks\": [my_stopper]}\n",
    "\n",
    "lstm_model = RNNModel(\n",
    "    model=\"LSTM\", \n",
    "    **best_params,\n",
    "    n_epochs=20,\n",
    "    training_length=best_params[\"input_chunk_length\"] * 2,\n",
    "    pl_trainer_kwargs=pl_trainer_kwargs,\n",
    "    force_reset=True\n",
    ")\n",
    "\n",
    "fit_model(lstm_model)\n",
    "\n",
    "# Evaluate\n",
    "eval_result = evaluation.cross_validation_without_refit2(\n",
    "    model=lstm_model,\n",
    "    prefix_series=val,\n",
    "    test_series=test,\n",
    "    metrics={\n",
    "        'rmse': rmse, \n",
    "        'co2_rmse': evaluation.co2_rmse, \n",
    "    },\n",
    "    data_scaler=smard_data_scaler,\n",
    "    covariates=covariates_time.stack(weather_data),\n",
    "    forecast_horizon=7*24,\n",
    ") \n",
    "\n",
    "eval_co2_rmse = eval_result['co2_rmse']\n",
    "print(f\"Eval CO2 RMSE: {eval_co2_rmse}\")\n",
    "\n",
    "lstm_model.save(\"models/best_model.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_model(model):\n",
    "    covariate_args = get_covariate_args(\n",
    "        model=model,\n",
    "        covariates=covariates_time.stack(weather_data),\n",
    "    )[0]\n",
    "    model.fit(series=train, val_series=val, **covariate_args)\n",
    "\n",
    "\n",
    "lags = [-1, -2, -3, -4, -8, -16, -24, -24 * 2, -24 * 7, -24 * 7 * 2, -24 * 7 * 4, -24 * 7 * 8]\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "\n",
    "    max_depth = trial.suggest_int('max_depth', 5, 10)\n",
    "    n_estimators = trial.suggest_int('n_estimators', 100, 1000)\n",
    "\n",
    "    print(f\"Trialing with {trial.params}\")\n",
    "\n",
    "    xgboost_model = XGBModel(\n",
    "        max_depth=max_depth,\n",
    "        n_estimators=n_estimators,\n",
    "        lags=lags,\n",
    "        lags_past_covariates=lags,\n",
    "        verbosity=0,\n",
    "    )\n",
    "\n",
    "    fit_model(xgboost_model)\n",
    "\n",
    "    # Evaluate\n",
    "    eval_result = evaluation.cross_validation_without_refit2(\n",
    "        model=xgboost_model,\n",
    "        prefix_series=train,\n",
    "        test_series=val,\n",
    "        metrics={\n",
    "            'rmse': rmse, \n",
    "            'co2_rmse': evaluation.co2_rmse, \n",
    "        },\n",
    "        data_scaler=smard_data_scaler,\n",
    "        covariates=covariates_time.stack(weather_data),\n",
    "        forecast_horizon=7*24,\n",
    "    ) \n",
    "\n",
    "    eval_co2_rmse = eval_result['co2_rmse']\n",
    "    print(f\"Eval CO2 RMSE: {eval_co2_rmse}\")\n",
    "\n",
    "    return eval_co2_rmse\n",
    "\n",
    "\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = {'max_depth': 9, 'n_estimators': 696} # study.best_params\n",
    "print(f\"Best params: {best_params}\")\n",
    "\n",
    "xgboost_model = XGBModel(**best_params, lags=lags, lags_past_covariates=lags, verbosity=0)\n",
    "\n",
    "fit_model(xgboost_model)\n",
    "\n",
    "# Evaluate\n",
    "eval_result = evaluation.cross_validation_without_refit2(\n",
    "    model=xgboost_model,\n",
    "    prefix_series=val,\n",
    "    test_series=test,\n",
    "    metrics={\n",
    "        'rmse': rmse, \n",
    "        'co2_rmse': evaluation.co2_rmse, \n",
    "    },\n",
    "    data_scaler=smard_data_scaler,\n",
    "    covariates=covariates_time.stack(weather_data),\n",
    "    forecast_horizon=7*24,\n",
    ") \n",
    "\n",
    "eval_co2_rmse = eval_result['co2_rmse']\n",
    "\n",
    "xgboost_model.save(\"models/best_model_xgboost.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Best params: {best_params}\")\n",
    "print(f\"Eval CO2 RMSE: {eval_co2_rmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
